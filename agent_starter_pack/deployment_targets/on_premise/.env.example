# On-Premise Deployment Environment Variables
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Configuration
# ============================================================================

# Option 1: Cloud Provider (OpenAI, Azure OpenAI, Together AI, etc.)
# LLM_ENDPOINT_URL=https://api.openai.com/v1
# LLM_MODEL_NAME=gpt-4o-mini
# LLM_API_KEY=sk-your-api-key-here

# Option 2: Local vLLM or TGI
LLM_ENDPOINT_URL=http://localhost:8001/v1
LLM_MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
LLM_API_KEY=secret-token-change-me

# Option 3: Ollama (no authentication required)
# LLM_ENDPOINT_URL=http://localhost:11434/v1
# LLM_MODEL_NAME=llama3.1:8b
# LLM_API_KEY=not-needed

# ============================================================================
# Embedding Configuration (for RAG agents only)
# ============================================================================

# Can use same endpoint as LLM or separate embedding service
EMBEDDING_ENDPOINT_URL=http://localhost:8001/v1
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# ============================================================================
# Database Configuration
# ============================================================================

# PostgreSQL connection for session state
DATABASE_URL=postgresql://agent_user:changeme@localhost:5432/agent_db
DB_USER=agent_user
DB_PASS=changeme
DB_NAME=agent_db

# For docker-compose, use service name instead of localhost
# DATABASE_URL=postgresql://agent_user:changeme@postgres:5432/agent_db

# ============================================================================
# Storage Configuration
# ============================================================================

# Storage backend type: local, minio, or s3
STORAGE_TYPE=local

# Local filesystem storage (when STORAGE_TYPE=local)
LOCAL_STORAGE_PATH=./data/storage

# MinIO configuration (when STORAGE_TYPE=minio)
STORAGE_ENDPOINT_URL=http://localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# ============================================================================
# Vector Database Configuration (for RAG agents)
# ============================================================================

# Vector DB type: chroma, weaviate, qdrant, or pgvector
VECTOR_DB_TYPE=chroma

# Chroma configuration (embedded or client-server)
VECTOR_DB_URL=http://localhost:8002
VECTOR_DB_PATH=./data/chroma

# Weaviate configuration
# VECTOR_DB_URL=http://localhost:8080
# WEAVIATE_API_KEY=your-api-key

# Qdrant configuration
# VECTOR_DB_URL=http://localhost:6333
# QDRANT_API_KEY=your-api-key

# ============================================================================
# Logging Configuration
# ============================================================================

LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE_PATH=./logs/agent.log

# Loki endpoint for centralized logging (optional)
# LOKI_URL=http://localhost:3100

# ============================================================================
# Tracing Configuration
# ============================================================================

# Enable distributed tracing
ENABLE_TRACING=false

# Tracing backend: jaeger, zipkin, or otlp
TRACING_BACKEND=jaeger

# Jaeger configuration
JAEGER_ENDPOINT=http://localhost:14268/api/traces
OTEL_EXPORTER_JAEGER_ENDPOINT=http://localhost:14250

# Zipkin configuration
# ZIPKIN_ENDPOINT=http://localhost:9411/api/v2/spans

# OpenTelemetry Collector
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# ============================================================================
# Observability (optional)
# ============================================================================

# Grafana admin password
GRAFANA_PASSWORD=admin

# Chroma telemetry
CHROMA_TELEMETRY=false

# ============================================================================
# Application Settings
# ============================================================================

APP_HOST=0.0.0.0
APP_PORT=8000
AGENT_VERSION=0.1.0

# CORS origins (comma-separated URLs, or leave empty for no CORS)
# ALLOW_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================================================
# External Service Tokens (for model download)
# ============================================================================

# HuggingFace token for downloading models (if using vLLM with HF models)
# HF_TOKEN=your_huggingface_token_here

# vLLM API key (must match LLM_API_KEY if using vLLM)
VLLM_API_KEY=secret-token-change-me
